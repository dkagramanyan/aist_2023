{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from skimage import io, transform, color, filters\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import disk, ball\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import imutils\n",
    "\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handwritten digit classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_test=x_test.reshape(-1,28,28,1)/255\n",
    "x_train=x_train.reshape(-1,28,28,1)/255\n",
    "y_test=tf.keras.utils.to_categorical(y_test)\n",
    "y_train=tf.keras.utils.to_categorical(y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.2, # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=256),\n",
    "                              epochs = 20, validation_data = (x_test,y_test),\n",
    "                              verbose = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.save_weights('mnist.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights('mnist.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def frame_image(img, frame_width):\n",
    "    b = frame_width # border size in pixel\n",
    "    ny, nx = img.shape[0], img.shape[1] # resolution / number of pixels in x and y\n",
    "    framed_img = np.ones((b+ny+b, b+nx+b))\n",
    "    framed_img[b:-b, b:-b] = img\n",
    "    return framed_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crop(gra_f):\n",
    "    mean_pixel_column=[]\n",
    "    for j in range(gra_f.shape[1]):\n",
    "        pixels=[]\n",
    "        for i in range(gra_f.shape[0]):\n",
    "            pixels.append(gra_f[i,j])\n",
    "        mean_pixel_column.append(np.mean(pixels))\n",
    "\n",
    "    deriv=np.gradient(mean_pixel_column)\n",
    "\n",
    "    fit1 = SimpleExpSmoothing(deriv).fit(smoothing_level=0.2,optimized=False).fittedvalues\n",
    "    plt.plot(deriv)\n",
    "    plt.plot(fit1)\n",
    "\n",
    "    x_min=find_peaks(fit1,)[0][0]\n",
    "\n",
    "    min_extremax=argrelextrema(fit1, np.less)[0]\n",
    "\n",
    "    if len(min_extremax)>1:\n",
    "        x_max=min_extremax[-2]\n",
    "    else:\n",
    "        x_max=min_extremax[-1]\n",
    "\n",
    "    return x_min, x_max\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# img=io.imread('4_c.jpg')\n",
    "# img=io.imread('empty_c.jpg')\n",
    "# img=io.imread('63106_31.jpg')\n",
    "# img=io.imread('images/'+'4_c_2.jpg')\n",
    "# img=io.imread('4_c_2_rect.jpg')\n",
    "# img=io.imread('4.jpg')\n",
    "# img=io.imread('3.jpg')\n",
    "# img=io.imread('images/'+'3_c.png')\n",
    "# img=io.imread('5.png')\n",
    "# img=io.imread('images/'+'5_c.png')\n",
    "img=io.imread('63106_12.jpg')\n",
    "# img=io.imread('error_c.jpg')\n",
    "\n",
    "gray=color.rgb2gray(img)\n",
    "\n",
    "gra_f=np.where(gray>0.9, gray, 0)\n",
    "gra_f=frame_image(gra_f,10)\n",
    "gra_f=1-gra_f\n",
    "\n",
    "thr=threshold_otsu(gra_f)\n",
    "gra_binary=gra_f>thr\n",
    "\n",
    "gra_f=np.where(gra_binary==True, gra_f, 0)\n",
    "\n",
    "y_min, y_max=crop(gra_f)\n",
    "\n",
    "N=20\n",
    "y_min=y_min-N\n",
    "if y_min<0:\n",
    "    y_min=0\n",
    "\n",
    "gra_f=gra_f[:, y_min:y_max+N]\n",
    "\n",
    "img_t=transform.resize(gra_f, (28,28,1))\n",
    "\n",
    "res=model.predict(tf.expand_dims(img_t,0))\n",
    "\n",
    "fig,(ax1,ax2, ax3)=plt.subplots(1,3, figsize=(15,6))\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(gra_f,cmap='gray')\n",
    "ax3.imshow(img_t,cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "for i in range(len(res[0])):\n",
    "    print(i,res[0,i])\n",
    "\n",
    "np.argmax(res)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_pixel_column=[]\n",
    "for j in range(gra_f.shape[1]):\n",
    "    pixels=[]\n",
    "    for i in range(gra_f.shape[0]):\n",
    "        pixels.append(gra_f[i,j])\n",
    "    mean_pixel_column.append(np.mean(pixels))\n",
    "\n",
    "deriv=np.gradient(mean_pixel_column)\n",
    "\n",
    "fit1 = SimpleExpSmoothing(deriv).fit(smoothing_level=0.2,optimized=False).fittedvalues\n",
    "\n",
    "\n",
    "x_min=find_peaks(fit1,)[0][0]\n",
    "# x_min=argrelextrema(fit1, np.greater)[0][-1]\n",
    "y_min=fit1[x_min]\n",
    "\n",
    "# peaks, _ = find_peaks(-fit1,)\n",
    "peaks= argrelextrema(fit1, np.less)[0]\n",
    "diffs=np.diff(peaks)\n",
    "\n",
    "# x_max=peaks[np.where(diffs>15)[0][-1]]\n",
    "x_max=argrelextrema(fit1, np.less)[0][-2]\n",
    "y_max=fit1[x_max]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(deriv)\n",
    "plt.plot(fit1)\n",
    "\n",
    "plt.scatter(x_min,y_min, s=150)\n",
    "plt.scatter(x_max,y_max,s=150)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_peaks(fit1,)[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1 is empty\n",
    "\n",
    "8 is \"проверено\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_paths=glob.glob('data/blanks_aligned_jpg/*.jpg')\n",
    "files_paths=[path.replace('\\\\','/')for path in files_paths]\n",
    "\n",
    "# save_folder='data/blanks_aligned_jpg/'\n",
    "\n",
    "\n",
    "preprocess_images=[]\n",
    "\n",
    "for path in tqdm(files_paths):\n",
    "    img=io.imread(path)\n",
    "    img=img[450:561,1162:1321]\n",
    "    img=img[10:-10, 10:-10]\n",
    "\n",
    "    gray=color.rgb2gray(img)\n",
    "\n",
    "    gra_f=np.where(gray>0.9, gray, 0)\n",
    "    gra_f=frame_image(gra_f,10)\n",
    "    gra_f=1-gra_f\n",
    "\n",
    "    thr=threshold_otsu(gra_f)\n",
    "    gra_binary=gra_f>thr\n",
    "\n",
    "    gra_f=np.where(gra_binary==True, gra_f, 0)\n",
    "\n",
    "    y_min, y_max=crop(gra_f)\n",
    "\n",
    "    N=20\n",
    "    y_min=y_min-N\n",
    "    if y_min<0:\n",
    "        y_min=0\n",
    "\n",
    "    gra_f=gra_f[:, y_min:y_max+N]\n",
    "\n",
    "    img_t=transform.resize(gra_f, (28,28,1))\n",
    "\n",
    "    preprocess_images.append(img_t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grades=[]\n",
    "\n",
    "for img in tqdm(preprocess_images):\n",
    "    res=model.predict(tf.expand_dims(img,0))\n",
    "    grade=np.argmax(res)\n",
    "\n",
    "    grades.append(grade)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grades_new=[]\n",
    "\n",
    "for grade in grades:\n",
    "    if grade==1:\n",
    "        grades_new.append(-1)\n",
    "    elif grade>5:\n",
    "        grades_new.append(0)\n",
    "    else:\n",
    "        grades_new.append(grade)\n",
    "\n",
    "plt.hist(grades_new, bins=8)\n",
    "plt.xticks(range(-1,6))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids=[path.split('/')[-1][:-4] for path in files_paths]\n",
    "df=pd.DataFrame({'ids':ids, 'grade':grades_new})\n",
    "\n",
    "df.to_csv('file_names_grades.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf2",
   "language": "python",
   "display_name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
